{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.chdir(os.getcwd() + \"/../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cofig import data_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1） Read Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_config.train_data_path,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "      <th>#1 string</th>\n",
       "      <th>#2 string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>amrozi accused his brother whom he called the ...</td>\n",
       "      <td>referring to him as only the witness amrozi ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>yucaipa owned dominicks before selling the cha...</td>\n",
       "      <td>yucaipa bought dominicks in 1995 for $693 mill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>they had published an advertisement on the int...</td>\n",
       "      <td>on june 10 the ships owners had published an a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>around 0335 gmt tab shares were up 19 cents or...</td>\n",
       "      <td>tab shares jumped 20 cents or 4.6% to set a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>the stock rose $2.11 or about 11 percent to cl...</td>\n",
       "      <td>pg&amp;e corp. shares jumped $1.63 or 8 percent to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quality                                          #1 string  \\\n",
       "0        1  amrozi accused his brother whom he called the ...   \n",
       "1        0  yucaipa owned dominicks before selling the cha...   \n",
       "2        1  they had published an advertisement on the int...   \n",
       "3        0  around 0335 gmt tab shares were up 19 cents or...   \n",
       "4        1  the stock rose $2.11 or about 11 percent to cl...   \n",
       "\n",
       "                                           #2 string  \n",
       "0  referring to him as only the witness amrozi ac...  \n",
       "1  yucaipa bought dominicks in 1995 for $693 mill...  \n",
       "2  on june 10 the ships owners had published an a...  \n",
       "3  tab shares jumped 20 cents or 4.6% to set a re...  \n",
       "4  pg&e corp. shares jumped $1.63 or 8 percent to...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = train_df['#1 string']\n",
    "\n",
    "text_2 = train_df['#2 string']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2） Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import clean_text,remove_stopwords,tokenize\n",
    "from corpus import read_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = list(train_df['#1 string'])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"amrozi accused his brother whom he called th\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_process import TextPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [clean_text,remove_stopwords,tokenize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessor = TextPreprocessor(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = text_preprocessor.transform(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {\"num_words\": None,\n",
    "                  'filters': '',\n",
    "                  \"lower\": True,\n",
    "                  'split': ' ',\n",
    "                  'char_level': False,\n",
    "                  'oov_token': None,\n",
    "                  'document_count': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(**default_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['distorting', 'evidence'],\n",
       "       ['5', 'billion'],\n",
       "       ['sale', 'added'],\n",
       "       ['4', '57'],\n",
       "       ['stock', 'exchange'],\n",
       "       ['year', 'earlier'],\n",
       "       ['15', 'friday'],\n",
       "       ['supreme', 'court'],\n",
       "       ['ago', 'period'],\n",
       "       ['growth', 'strategy']], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.sequence.pad_sequences(text_list, padding='post',dtype=np.object,value = 'EOS',maxlen=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['amrozi', 'accused', 'brother', 'called', 'witness',\n",
       "        'deliberately', 'distorting', 'evidence', 'EOS', 'EOS', 'EOS',\n",
       "        'EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS'],\n",
       "       ['yucaipa', 'owned', 'dominicks', 'selling', 'chain', 'safeway',\n",
       "        '1998', '2', '5', 'billion', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS',\n",
       "        'EOS', 'EOS'],\n",
       "       ['published', 'advertisement', 'internet', 'june', '10',\n",
       "        'offering', 'cargo', 'sale', 'added', 'EOS', 'EOS', 'EOS', 'EOS',\n",
       "        'EOS', 'EOS', 'EOS', 'EOS'],\n",
       "       ['around', '0335', 'gmt', 'tab', 'shares', '19', 'cents', '4',\n",
       "        '4', '4', '56', 'earlier', 'set', 'record', 'high', '4', '57'],\n",
       "       ['stock', 'rose', '2', '11', '11', 'percent', 'close', 'friday',\n",
       "        '21', '51', 'new', 'york', 'stock', 'exchange', 'EOS', 'EOS',\n",
       "        'EOS'],\n",
       "       ['revenue', 'first', 'quarter', 'year', 'dropped', '15',\n",
       "        'percent', 'period', 'year', 'earlier', 'EOS', 'EOS', 'EOS',\n",
       "        'EOS', 'EOS', 'EOS', 'EOS'],\n",
       "       ['nasdaq', 'weekly', 'gain', '17', '27', '1', '2', 'percent',\n",
       "        'closing', '1520', '15', 'friday', 'EOS', 'EOS', 'EOS', 'EOS',\n",
       "        'EOS'],\n",
       "       ['dvd', 'cca', 'appealed', 'state', 'supreme', 'court', 'EOS',\n",
       "        'EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS',\n",
       "        'EOS'],\n",
       "       ['compared', '35', '18', 'million', '24', 'cents', 'per', 'share',\n",
       "        'year', 'ago', 'period', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS',\n",
       "        'EOS'],\n",
       "       ['said', 'foodservice', 'pie', 'business', 'doesnt', 'fit',\n",
       "        'companys', 'long', 'term', 'growth', 'strategy', 'EOS', 'EOS',\n",
       "        'EOS', 'EOS', 'EOS', 'EOS']], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.sequence.pad_sequences(text_list, padding='post',dtype=np.object,value = 'EOS',maxlen=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Update Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading the word2vec matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "516783it [01:24, 6125.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Completed !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec_matrix = read_word2vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_matrix['love'].reshape(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_matrix['love'].reshape(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000827]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(word2vec_matrix['love'].reshape(1,-1),word2vec_matrix['love'].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(vec_1,vec_2):\n",
    "    return np.dot(vec_1.reshape(1,-1),vec_2.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_1 = np.random.uniform(-0.1,0.1,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_2 = np.random.uniform(-0.1,0.1,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04197309]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product(vec_1,vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec_matrix['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_word2vec_matrix(words_list,word2vec_matrix):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {\"num_words\": None,\n",
    "                  'filters': '',\n",
    "                  \"lower\": True,\n",
    "                  'split': ' ',\n",
    "                  'char_level': False,\n",
    "                  'oov_token': None,\n",
    "                  'document_count': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(**default_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor = tokenizer.texts_to_sequences(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 13, 14, 15, 16, 17, 18, 19,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0],\n",
       "       [20, 21, 22, 23, 24, 25, 26,  2, 27, 28,  0,  0,  0,  0,  0,  0,\n",
       "         0],\n",
       "       [29, 30, 31, 32, 33, 34, 35, 36, 37,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0],\n",
       "       [38, 39, 40, 41, 42, 43,  5,  1,  1,  1, 44,  6, 45, 46, 47,  1,\n",
       "        48],\n",
       "       [ 7, 49,  2,  8,  8,  3, 50,  9, 51, 52, 53, 54,  7, 55,  0,  0,\n",
       "         0],\n",
       "       [56, 57, 58,  4, 59, 10,  3, 11,  4,  6,  0,  0,  0,  0,  0,  0,\n",
       "         0],\n",
       "       [60, 61, 62, 63, 64, 65,  2,  3, 66, 67, 10,  9,  0,  0,  0,  0,\n",
       "         0],\n",
       "       [68, 69, 70, 71, 72, 73,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0],\n",
       "       [74, 75, 76, 77, 78,  5, 79, 80,  4, 81, 11,  0,  0,  0,  0,  0,\n",
       "         0],\n",
       "       [82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92,  0,  0,  0,  0,  0,\n",
       "         0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24, 25, 26, 2, 27, 28],\n",
       " [29, 30, 31, 32, 33, 34, 35, 36, 37],\n",
       " [38, 39, 40, 41, 42, 43, 5, 1, 1, 1, 44, 6, 45, 46, 47, 1, 48],\n",
       " [7, 49, 2, 8, 8, 3, 50, 9, 51, 52, 53, 54, 7, 55],\n",
       " [56, 57, 58, 4, 59, 10, 3, 11, 4, 6],\n",
       " [60, 61, 62, 63, 64, 65, 2, 3, 66, 67, 10, 9],\n",
       " [68, 69, 70, 71, 72, 73],\n",
       " [74, 75, 76, 77, 78, 5, 79, 80, 4, 81, 11],\n",
       " [82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "676it [00:00, 6710.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading the word2vec matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "516783it [01:02, 8297.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Completed !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec_matrix = read_word2vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
